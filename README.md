# Titanic-Survival-Prediction-Project-


The Titanic Survival prediction project  a thrilling voyage of discovery, analysis, modelling, and the chance to compete in a real-world machine learning challenge, whether you are new to data science or wanting to hone your abilities.
Let's go out on this thrilling journey to forecast Titanic passenger survival and reveal the data's secret mysteries!

The datasets is imported from kaggle 
# Project Summary -
1) Age Distribution: The age distribution of Titanic passengers reveals a diverse range, including infants, children, teenagers, young adults, and seniors. This variation suggests the need to categorize passengers into age groups for analysis.

2) Gender Disparity: The gender composition of passengers shows a significant gender disparity, with a higher number of males compared to females. This gender imbalance can be an important factor in predicting survival rates.

3) Passenger Class: The Titanic had passengers divided into three classes, with the majority in the third class (lower class). The distribution of passengers across classes can have implications for survival rates, as higher-class passengers may have had better access to lifeboats.

4) Survival Rate by Age: Analyzing the survival rates by age group reveals key trends. Children and babies had a notably higher survival rate, likely due to the "women and children first" policy during the evacuation. However, older passengers (seniors) had a lower survival rate, possibly due to physical limitations during the evacuation. Young adults exhibited varying survival rates.

5) Title Engineering: The creation of new features based on passenger titles (e.g., Mr., Mrs., Miss) allowed for a more granular categorization of passengers. This feature engineering improved model performance by considering the societal roles and gender associated with titles.

6) Model Performance: The project involved training and evaluating multiple machine learning models. Among these, the Support Vector Machine (SVM) with a radial kernel and the Decision Tree model emerged as the top-performing models for predicting passenger survival. These models were able to capture complex relationships in the data.

7) Accuracy Scores: The selected models achieved reasonable accuracy scores when making predictions on the test dataset. This indicates that the models had a predictive ability to classify passengers as survivors or non-survivors, though further improvements can always be explored.

8) Cross-Validation: Cross-validation played a crucial role in assessing the models' generalization performance. By dividing the training data into subsets and evaluating the model's performance on each subset, it helped identify potential overfitting and provided more robust estimates of model accuracy.

9) Hyperparameter Tuning: Hyperparameter tuning was employed to optimize model parameters and fine-tune their performance. Techniques like Grid Search allowed for systematic exploration of hyperparameter combinations to enhance model accuracy.

10) Submission to Kaggle: The final step of the project involved making predictions on the test dataset and preparing the results for submission to the Kaggle competition. This process demonstrated the practical application of the models for real-world predictions.
